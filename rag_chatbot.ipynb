{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Business Problem:\n",
        "Developing an AI \"Q&A chatbot\" equipped with the capability to stay abreast of the latest advancements across diverse research domains.\n",
        "\n",
        "# Uses:\n",
        "* **Efficient Research Assistance:** The chatbot serves as a valuable tool for researchers, aiding in the writing process by providing citations and suggesting relevant coursework materials. This enhances efficiency in literature review and ensures the inclusion of the most recent findings.\n",
        "\n",
        "* **Time and Effort Savings:** By automating the search for pertinent research materials, the chatbot significantly reduces the time and effort required for information gathering. Researchers can focus more on analysis and interpretation, thereby expediting the overall research process.\n",
        "\n",
        "* **Practical Application for Industry Experts:** The chatbot's ability to stay updated with recent advancements enables industry experts to practically apply new findings. This ensures that professionals can seamlessly integrate the latest knowledge into their work, fostering innovation and staying ahead in their respective fields.\n",
        "\n",
        "* **Interactive Learning:** Researchers and industry experts can engage in meaningful conversations with the chatbot, asking specific questions about recent research developments. This interactive learning experience facilitates a deeper understanding of complex topics and promotes continuous learning.\n",
        "\n",
        "# Implementation:\n",
        "1. Accessing OpenAI model through API as a base model.\n",
        "2. Creating text embeddings with OpenAI Langchain Embeddings.\n",
        "3. Storing Embeddings in Pinecone vector database.\n",
        "4. Quering and finding top 3 results by expanding LLM knowledge base.\n",
        "5. Gaining Inference and results."
      ],
      "metadata": {
        "id": "mhlNrIG36lyg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Dependencies"
      ],
      "metadata": {
        "id": "kr_ldHN5tpLW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p30-IloljKIl"
      },
      "outputs": [],
      "source": [
        "!pip install -qU \\\n",
        "langchain==0.0.354 \\\n",
        "openai==1.6.1 \\\n",
        "datasets==2.10.1 \\\n",
        "pinecone-client==3.0.0 \\\n",
        "tiktoken==0.5.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accessing API Keys"
      ],
      "metadata": {
        "id": "2h17d402t1Ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQelmA8bC_D6",
        "outputId": "894dcb04-3c82-48ef-a118-b7977eca671f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"drive/MyDrive/keys.json\", \"r\") as keys:\n",
        "  data = json.load(keys)\n",
        "  OPEN_API_KEY, PINECONE_API_KEY = data[\"OPEN_API_KEY\"], data[\"PINECONE_API_KEY\"]"
      ],
      "metadata": {
        "id": "ox_UwhbCkX8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing Model"
      ],
      "metadata": {
        "id": "axcPqBunt_3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "os.environ[OPEN_API_KEY] = os.getenv(OPEN_API_KEY) or OPEN_API_KEY\n",
        "\n",
        "chat = ChatOpenAI(\n",
        "    openai_api_key=os.environ[OPEN_API_KEY],\n",
        "    model=\"gpt-3.5-turbo\"\n",
        ")"
      ],
      "metadata": {
        "id": "y3sk1Zl3jn_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# System Prompting (Fine Tuning)"
      ],
      "metadata": {
        "id": "v0yHm5UV-VUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
        "\n",
        "message = [\n",
        "    SystemMessage(content=\"[Context] You are the AI behind a cutting-edge Q&A bot dedicated\\\n",
        "     to providing in-depth STEM knowledge to users for better understanding. \\\n",
        "     [Clarity] Craft clear and concise responses that deliver accurate information. \\\n",
        "     [Context Establishment] Assume users are seeking explanations, clarifications, \\\n",
        "     or insights on various STEM topics. [Examples] Include illustrative examples to \\\n",
        "     enhance the explanatory nature of the responses. [Gradual Refinement] If initial \\\n",
        "     responses lack depth, guide the model to delve deeper into specific concepts or \\\n",
        "     provide additional details. [Control Tokens] Use system messages to emphasize the \\\n",
        "     importance of accuracy and user-friendly explanations. [Temperature and Max Tokens] \\\n",
        "     Set temperature to 0.7 for a balanced blend of creativity and accuracy. Limit \\\n",
        "     responses to 150 tokens to ensure concise yet informative answers. [Experimentation] \\\n",
        "     Periodically experiment with variations of prompts to fine-tune the model's responses.\"),\n",
        "]"
      ],
      "metadata": {
        "id": "Jrcaff7Ikwhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = chat(message)\n",
        "print(res.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekDAo2PWl8F8",
        "outputId": "6721e17a-90b7-41b9-fe6b-00491cc328b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To calculate the volume of a rectangular prism, you need to multiply its length, width, and height. The formula for the volume of a rectangular prism is V = lwh, where V represents the volume, l represents the length, w represents the width, and h represents the height.\n",
            "\n",
            "For example, let's say you have a rectangular prism with a length of 5 units, a width of 3 units, and a height of 2 units. To find its volume, you can use the formula V = 5 * 3 * 2 = 30 cubic units.\n",
            "\n",
            "Remember to use consistent units when calculating volume. If the dimensions are given in different units, you may need to convert them to the same unit before multiplying them together.\n",
            "\n",
            "Keep in mind that the volume of a rectangular prism represents the amount of space it occupies in three dimensions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset"
      ],
      "metadata": {
        "id": "1EDHr0voFxCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\n",
        "    \"jamescalam/llama-2-arxiv-papers-chunked\",\n",
        "    split=\"train\"\n",
        ")\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVbvWMPkrZ1v",
        "outputId": "435329d9-78c9-47a4-8394-10b3035a08fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/jamescalam___json/jamescalam--llama-2-arxiv-papers-chunked-ea255a807f3039a6/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['doi', 'chunk-id', 'chunk', 'id', 'title', 'summary', 'source', 'authors', 'categories', 'comment', 'journal_ref', 'primary_category', 'published', 'updated', 'references'],\n",
              "    num_rows: 4838\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee3jt2nUtcg7",
        "outputId": "e9b54ebc-d521-4ade-bf14-36cc54789752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'doi': '1102.0183',\n",
              " 'chunk-id': '0',\n",
              " 'chunk': 'High-Performance Neural Networks\\nfor Visual Object Classi\\x0ccation\\nDan C. Cire\\x18 san, Ueli Meier, Jonathan Masci,\\nLuca M. Gambardella and J\\x7f urgen Schmidhuber\\nTechnical Report No. IDSIA-01-11\\nJanuary 2011\\nIDSIA / USI-SUPSI\\nDalle Molle Institute for Arti\\x0ccial Intelligence\\nGalleria 2, 6928 Manno, Switzerland\\nIDSIA is a joint institute of both University of Lugano (USI) and University of Applied Sciences of Southern Switzerland (SUPSI),\\nand was founded in 1988 by the Dalle Molle Foundation which promoted quality of life.\\nThis work was partially supported by the Swiss Commission for Technology and Innovation (CTI), Project n. 9688.1 IFF:\\nIntelligent Fill in Form.arXiv:1102.0183v1  [cs.AI]  1 Feb 2011\\nTechnical Report No. IDSIA-01-11 1\\nHigh-Performance Neural Networks\\nfor Visual Object Classi\\x0ccation\\nDan C. Cire\\x18 san, Ueli Meier, Jonathan Masci,\\nLuca M. Gambardella and J\\x7f urgen Schmidhuber\\nJanuary 2011\\nAbstract\\nWe present a fast, fully parameterizable GPU implementation of Convolutional Neural\\nNetwork variants. Our feature extractors are neither carefully designed nor pre-wired, but',\n",
              " 'id': '1102.0183',\n",
              " 'title': 'High-Performance Neural Networks for Visual Object Classification',\n",
              " 'summary': 'We present a fast, fully parameterizable GPU implementation of Convolutional\\nNeural Network variants. Our feature extractors are neither carefully designed\\nnor pre-wired, but rather learned in a supervised way. Our deep hierarchical\\narchitectures achieve the best published results on benchmarks for object\\nclassification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with\\nerror rates of 2.53%, 19.51%, 0.35%, respectively. Deep nets trained by simple\\nback-propagation perform better than more shallow ones. Learning is\\nsurprisingly rapid. NORB is completely trained within five epochs. Test error\\nrates on MNIST drop to 2.42%, 0.97% and 0.48% after 1, 3 and 17 epochs,\\nrespectively.',\n",
              " 'source': 'http://arxiv.org/pdf/1102.0183',\n",
              " 'authors': ['Dan C. Cireşan',\n",
              "  'Ueli Meier',\n",
              "  'Jonathan Masci',\n",
              "  'Luca M. Gambardella',\n",
              "  'Jürgen Schmidhuber'],\n",
              " 'categories': ['cs.AI', 'cs.NE'],\n",
              " 'comment': '12 pages, 2 figures, 5 tables',\n",
              " 'journal_ref': None,\n",
              " 'primary_category': 'cs.AI',\n",
              " 'published': '20110201',\n",
              " 'updated': '20110201',\n",
              " 'references': []}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Embeddings"
      ],
      "metadata": {
        "id": "70ox170Z-MF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "embed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=OPEN_API_KEY)"
      ],
      "metadata": {
        "id": "YQnPQjGb6aK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    'This is a test example for verifying shape of embedded texts!',\n",
        "]\n",
        "\n",
        "res = embed_model.embed_documents(texts)\n",
        "len(res), len(res[0]) # Visualizing Embedding size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnQECqMT6qrL",
        "outputId": "73405717-2032-4a23-8de0-a1f96128915c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1536)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intializing Vector Knowledge Base \"PineCone\""
      ],
      "metadata": {
        "id": "7HddUo6jF6Jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone\n",
        "from pinecone import ServerlessSpec\n",
        "\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "\n",
        "spec = ServerlessSpec(\n",
        "    cloud=\"GCP\", region=\"us-central1\"\n",
        ")"
      ],
      "metadata": {
        "id": "TL4ajjkWuz3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "index_name = 'rag-index-api' # Name of index in pinecone\n",
        "existing_indexes = [\n",
        "    index_info[\"name\"] for index_info in pc.list_indexes()\n",
        "]"
      ],
      "metadata": {
        "id": "OL9B52jS1uOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if index_name not in existing_indexes:\n",
        "    pc.create_index(\n",
        "        index_name,\n",
        "        dimension=1536,\n",
        "        metric='dotproduct',\n",
        "        spec=spec\n",
        "    )\n",
        "    while not pc.describe_index(index_name).status['ready']:\n",
        "        time.sleep(1) # Adding latency for rate limit\n",
        "\n",
        "index = pc.Index(index_name)\n",
        "time.sleep(1)\n",
        "index.describe_index_stats()"
      ],
      "metadata": {
        "id": "LqQXUBIsvsvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebfcfae0-cbbe-4fc5-de81-abe354f4bc2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.04838,\n",
              " 'namespaces': {'': {'vector_count': 4838}},\n",
              " 'total_vector_count': 4838}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing data in pandas dataframe"
      ],
      "metadata": {
        "id": "8h274MSO-295"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "data = dataset.to_pandas()\n",
        "data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3mWM31Rf7LLG",
        "outputId": "7f1c913f-c765-4f6f-efb1-ca742f6e6bc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         doi chunk-id                                              chunk  \\\n",
              "0  1102.0183        0  High-Performance Neural Networks\\nfor Visual O...   \n",
              "1  1102.0183        1  January 2011\\nAbstract\\nWe present a fast, ful...   \n",
              "2  1102.0183        2  promising architectures for such tasks. The mo...   \n",
              "3  1102.0183        3  Mutch and Lowe, 2008), whose \n",
              "lters are \n",
              "xed, ...   \n",
              "4  1102.0183        4  We evaluate various networks on the handwritte...   \n",
              "5  1102.0183        5  (Fukushima, 2003) helps to improve the recogni...   \n",
              "6  1102.0183        6  2.3 Max-pooling layer\\nThe biggest architectur...   \n",
              "7  1102.0183        7  into a 1D feature vector. The top layer is alw...   \n",
              "8  1102.0183        8  strategy is fast enough. We use the following ...   \n",
              "9  1102.0183        9  Weights (AW) CUDA kernels. The second column s...   \n",
              "\n",
              "          id                                              title  \\\n",
              "0  1102.0183  High-Performance Neural Networks for Visual Ob...   \n",
              "1  1102.0183  High-Performance Neural Networks for Visual Ob...   \n",
              "2  1102.0183  High-Performance Neural Networks for Visual Ob...   \n",
              "3  1102.0183  High-Performance Neural Networks for Visual Ob...   \n",
              "4  1102.0183  High-Performance Neural Networks for Visual Ob...   \n",
              "5  1102.0183  High-Performance Neural Networks for Visual Ob...   \n",
              "6  1102.0183  High-Performance Neural Networks for Visual Ob...   \n",
              "7  1102.0183  High-Performance Neural Networks for Visual Ob...   \n",
              "8  1102.0183  High-Performance Neural Networks for Visual Ob...   \n",
              "9  1102.0183  High-Performance Neural Networks for Visual Ob...   \n",
              "\n",
              "                                             summary  \\\n",
              "0  We present a fast, fully parameterizable GPU i...   \n",
              "1  We present a fast, fully parameterizable GPU i...   \n",
              "2  We present a fast, fully parameterizable GPU i...   \n",
              "3  We present a fast, fully parameterizable GPU i...   \n",
              "4  We present a fast, fully parameterizable GPU i...   \n",
              "5  We present a fast, fully parameterizable GPU i...   \n",
              "6  We present a fast, fully parameterizable GPU i...   \n",
              "7  We present a fast, fully parameterizable GPU i...   \n",
              "8  We present a fast, fully parameterizable GPU i...   \n",
              "9  We present a fast, fully parameterizable GPU i...   \n",
              "\n",
              "                           source  \\\n",
              "0  http://arxiv.org/pdf/1102.0183   \n",
              "1  http://arxiv.org/pdf/1102.0183   \n",
              "2  http://arxiv.org/pdf/1102.0183   \n",
              "3  http://arxiv.org/pdf/1102.0183   \n",
              "4  http://arxiv.org/pdf/1102.0183   \n",
              "5  http://arxiv.org/pdf/1102.0183   \n",
              "6  http://arxiv.org/pdf/1102.0183   \n",
              "7  http://arxiv.org/pdf/1102.0183   \n",
              "8  http://arxiv.org/pdf/1102.0183   \n",
              "9  http://arxiv.org/pdf/1102.0183   \n",
              "\n",
              "                                             authors      categories  \\\n",
              "0  [Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...  [cs.AI, cs.NE]   \n",
              "1  [Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...  [cs.AI, cs.NE]   \n",
              "2  [Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...  [cs.AI, cs.NE]   \n",
              "3  [Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...  [cs.AI, cs.NE]   \n",
              "4  [Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...  [cs.AI, cs.NE]   \n",
              "5  [Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...  [cs.AI, cs.NE]   \n",
              "6  [Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...  [cs.AI, cs.NE]   \n",
              "7  [Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...  [cs.AI, cs.NE]   \n",
              "8  [Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...  [cs.AI, cs.NE]   \n",
              "9  [Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...  [cs.AI, cs.NE]   \n",
              "\n",
              "                         comment journal_ref primary_category published  \\\n",
              "0  12 pages, 2 figures, 5 tables        None            cs.AI  20110201   \n",
              "1  12 pages, 2 figures, 5 tables        None            cs.AI  20110201   \n",
              "2  12 pages, 2 figures, 5 tables        None            cs.AI  20110201   \n",
              "3  12 pages, 2 figures, 5 tables        None            cs.AI  20110201   \n",
              "4  12 pages, 2 figures, 5 tables        None            cs.AI  20110201   \n",
              "5  12 pages, 2 figures, 5 tables        None            cs.AI  20110201   \n",
              "6  12 pages, 2 figures, 5 tables        None            cs.AI  20110201   \n",
              "7  12 pages, 2 figures, 5 tables        None            cs.AI  20110201   \n",
              "8  12 pages, 2 figures, 5 tables        None            cs.AI  20110201   \n",
              "9  12 pages, 2 figures, 5 tables        None            cs.AI  20110201   \n",
              "\n",
              "    updated references  \n",
              "0  20110201         []  \n",
              "1  20110201         []  \n",
              "2  20110201         []  \n",
              "3  20110201         []  \n",
              "4  20110201         []  \n",
              "5  20110201         []  \n",
              "6  20110201         []  \n",
              "7  20110201         []  \n",
              "8  20110201         []  \n",
              "9  20110201         []  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b4afa03-609d-45cf-a038-25a774b42c7f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doi</th>\n",
              "      <th>chunk-id</th>\n",
              "      <th>chunk</th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>summary</th>\n",
              "      <th>source</th>\n",
              "      <th>authors</th>\n",
              "      <th>categories</th>\n",
              "      <th>comment</th>\n",
              "      <th>journal_ref</th>\n",
              "      <th>primary_category</th>\n",
              "      <th>published</th>\n",
              "      <th>updated</th>\n",
              "      <th>references</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1102.0183</td>\n",
              "      <td>0</td>\n",
              "      <td>High-Performance Neural Networks\\nfor Visual O...</td>\n",
              "      <td>1102.0183</td>\n",
              "      <td>High-Performance Neural Networks for Visual Ob...</td>\n",
              "      <td>We present a fast, fully parameterizable GPU i...</td>\n",
              "      <td>http://arxiv.org/pdf/1102.0183</td>\n",
              "      <td>[Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...</td>\n",
              "      <td>[cs.AI, cs.NE]</td>\n",
              "      <td>12 pages, 2 figures, 5 tables</td>\n",
              "      <td>None</td>\n",
              "      <td>cs.AI</td>\n",
              "      <td>20110201</td>\n",
              "      <td>20110201</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1102.0183</td>\n",
              "      <td>1</td>\n",
              "      <td>January 2011\\nAbstract\\nWe present a fast, ful...</td>\n",
              "      <td>1102.0183</td>\n",
              "      <td>High-Performance Neural Networks for Visual Ob...</td>\n",
              "      <td>We present a fast, fully parameterizable GPU i...</td>\n",
              "      <td>http://arxiv.org/pdf/1102.0183</td>\n",
              "      <td>[Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...</td>\n",
              "      <td>[cs.AI, cs.NE]</td>\n",
              "      <td>12 pages, 2 figures, 5 tables</td>\n",
              "      <td>None</td>\n",
              "      <td>cs.AI</td>\n",
              "      <td>20110201</td>\n",
              "      <td>20110201</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1102.0183</td>\n",
              "      <td>2</td>\n",
              "      <td>promising architectures for such tasks. The mo...</td>\n",
              "      <td>1102.0183</td>\n",
              "      <td>High-Performance Neural Networks for Visual Ob...</td>\n",
              "      <td>We present a fast, fully parameterizable GPU i...</td>\n",
              "      <td>http://arxiv.org/pdf/1102.0183</td>\n",
              "      <td>[Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...</td>\n",
              "      <td>[cs.AI, cs.NE]</td>\n",
              "      <td>12 pages, 2 figures, 5 tables</td>\n",
              "      <td>None</td>\n",
              "      <td>cs.AI</td>\n",
              "      <td>20110201</td>\n",
              "      <td>20110201</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1102.0183</td>\n",
              "      <td>3</td>\n",
              "      <td>Mutch and Lowe, 2008), whose \flters are \fxed, ...</td>\n",
              "      <td>1102.0183</td>\n",
              "      <td>High-Performance Neural Networks for Visual Ob...</td>\n",
              "      <td>We present a fast, fully parameterizable GPU i...</td>\n",
              "      <td>http://arxiv.org/pdf/1102.0183</td>\n",
              "      <td>[Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...</td>\n",
              "      <td>[cs.AI, cs.NE]</td>\n",
              "      <td>12 pages, 2 figures, 5 tables</td>\n",
              "      <td>None</td>\n",
              "      <td>cs.AI</td>\n",
              "      <td>20110201</td>\n",
              "      <td>20110201</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1102.0183</td>\n",
              "      <td>4</td>\n",
              "      <td>We evaluate various networks on the handwritte...</td>\n",
              "      <td>1102.0183</td>\n",
              "      <td>High-Performance Neural Networks for Visual Ob...</td>\n",
              "      <td>We present a fast, fully parameterizable GPU i...</td>\n",
              "      <td>http://arxiv.org/pdf/1102.0183</td>\n",
              "      <td>[Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...</td>\n",
              "      <td>[cs.AI, cs.NE]</td>\n",
              "      <td>12 pages, 2 figures, 5 tables</td>\n",
              "      <td>None</td>\n",
              "      <td>cs.AI</td>\n",
              "      <td>20110201</td>\n",
              "      <td>20110201</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1102.0183</td>\n",
              "      <td>5</td>\n",
              "      <td>(Fukushima, 2003) helps to improve the recogni...</td>\n",
              "      <td>1102.0183</td>\n",
              "      <td>High-Performance Neural Networks for Visual Ob...</td>\n",
              "      <td>We present a fast, fully parameterizable GPU i...</td>\n",
              "      <td>http://arxiv.org/pdf/1102.0183</td>\n",
              "      <td>[Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...</td>\n",
              "      <td>[cs.AI, cs.NE]</td>\n",
              "      <td>12 pages, 2 figures, 5 tables</td>\n",
              "      <td>None</td>\n",
              "      <td>cs.AI</td>\n",
              "      <td>20110201</td>\n",
              "      <td>20110201</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1102.0183</td>\n",
              "      <td>6</td>\n",
              "      <td>2.3 Max-pooling layer\\nThe biggest architectur...</td>\n",
              "      <td>1102.0183</td>\n",
              "      <td>High-Performance Neural Networks for Visual Ob...</td>\n",
              "      <td>We present a fast, fully parameterizable GPU i...</td>\n",
              "      <td>http://arxiv.org/pdf/1102.0183</td>\n",
              "      <td>[Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...</td>\n",
              "      <td>[cs.AI, cs.NE]</td>\n",
              "      <td>12 pages, 2 figures, 5 tables</td>\n",
              "      <td>None</td>\n",
              "      <td>cs.AI</td>\n",
              "      <td>20110201</td>\n",
              "      <td>20110201</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1102.0183</td>\n",
              "      <td>7</td>\n",
              "      <td>into a 1D feature vector. The top layer is alw...</td>\n",
              "      <td>1102.0183</td>\n",
              "      <td>High-Performance Neural Networks for Visual Ob...</td>\n",
              "      <td>We present a fast, fully parameterizable GPU i...</td>\n",
              "      <td>http://arxiv.org/pdf/1102.0183</td>\n",
              "      <td>[Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...</td>\n",
              "      <td>[cs.AI, cs.NE]</td>\n",
              "      <td>12 pages, 2 figures, 5 tables</td>\n",
              "      <td>None</td>\n",
              "      <td>cs.AI</td>\n",
              "      <td>20110201</td>\n",
              "      <td>20110201</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1102.0183</td>\n",
              "      <td>8</td>\n",
              "      <td>strategy is fast enough. We use the following ...</td>\n",
              "      <td>1102.0183</td>\n",
              "      <td>High-Performance Neural Networks for Visual Ob...</td>\n",
              "      <td>We present a fast, fully parameterizable GPU i...</td>\n",
              "      <td>http://arxiv.org/pdf/1102.0183</td>\n",
              "      <td>[Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...</td>\n",
              "      <td>[cs.AI, cs.NE]</td>\n",
              "      <td>12 pages, 2 figures, 5 tables</td>\n",
              "      <td>None</td>\n",
              "      <td>cs.AI</td>\n",
              "      <td>20110201</td>\n",
              "      <td>20110201</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1102.0183</td>\n",
              "      <td>9</td>\n",
              "      <td>Weights (AW) CUDA kernels. The second column s...</td>\n",
              "      <td>1102.0183</td>\n",
              "      <td>High-Performance Neural Networks for Visual Ob...</td>\n",
              "      <td>We present a fast, fully parameterizable GPU i...</td>\n",
              "      <td>http://arxiv.org/pdf/1102.0183</td>\n",
              "      <td>[Dan C. Cireşan, Ueli Meier, Jonathan Masci, L...</td>\n",
              "      <td>[cs.AI, cs.NE]</td>\n",
              "      <td>12 pages, 2 figures, 5 tables</td>\n",
              "      <td>None</td>\n",
              "      <td>cs.AI</td>\n",
              "      <td>20110201</td>\n",
              "      <td>20110201</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b4afa03-609d-45cf-a038-25a774b42c7f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7b4afa03-609d-45cf-a038-25a774b42c7f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7b4afa03-609d-45cf-a038-25a774b42c7f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ebfda66c-2e8f-4357-972e-89fb1404cae0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ebfda66c-2e8f-4357-972e-89fb1404cae0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ebfda66c-2e8f-4357-972e-89fb1404cae0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating and Adding Embeddings to Vector Database"
      ],
      "metadata": {
        "id": "gbPtS_D9_0MI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delay = 20\n",
        "batch_size = 100\n",
        "\n",
        "for i in tqdm(range(0, len(data), batch_size)):\n",
        "    i_end = min(len(data), i+batch_size)\n",
        "    batch = data.iloc[i:i_end]\n",
        "    ids = [f\"{x['doi']}-{x['chunk-id']}\" for i, x in batch.iterrows()]\n",
        "    texts = [x['chunk'] for _, x in batch.iterrows()]\n",
        "    embeds = embed_model.embed_documents(texts)\n",
        "    metadata = [\n",
        "        {'text': x['chunk'],\n",
        "         'source': x['source'],\n",
        "         'title': x['title']} for i, x in batch.iterrows()\n",
        "    ]\n",
        "    index.upsert(vectors=zip(ids, embeds, metadata))\n",
        "\n",
        "    time.sleep(delay)"
      ],
      "metadata": {
        "id": "XIjKhjxC7Y_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.describe_index_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzjKVn7wi2Ip",
        "outputId": "a4bd4b61-85ba-45de-82ac-9acce18ef64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.04838,\n",
              " 'namespaces': {'': {'vector_count': 4838}},\n",
              " 'total_vector_count': 4838}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding Result Similarity"
      ],
      "metadata": {
        "id": "R_BR8QmNrLlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "text_field = \"text\" # From the metadata that was created earlier\n",
        "\n",
        "# Initializing the vector store object\n",
        "vectorstore = Pinecone(index, embed_model.embed_query, text_field)"
      ],
      "metadata": {
        "id": "D91sj1mv7mdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1626d00f-4dd2-4d59-a34e-6189e4d57a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/pinecone.py:75: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modifying Prompt"
      ],
      "metadata": {
        "id": "aPwM4j4UrWHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modified_prompt(query):\n",
        "  yields = vectorstore.similarity_search(query, k=3)\n",
        "\n",
        "  knowledge_base = \"\\n\".join([x.page_content for x in yields])\n",
        "\n",
        "  new_prompt = f\"\"\"Using the contexts below, answer the query.\n",
        "\n",
        "  Contexts:\n",
        "  {knowledge_base}\n",
        "\n",
        "  Query:\n",
        "  {query}\"\"\"\n",
        "\n",
        "  return new_prompt"
      ],
      "metadata": {
        "id": "x6divr24A_Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conversate(query: str):\n",
        "  # Human prompt\n",
        "  prompt = HumanMessage(\n",
        "      content=modified_prompt(query)\n",
        "      )\n",
        "\n",
        "  message.append(prompt)\n",
        "\n",
        "  res = chat(message)\n",
        "\n",
        "  # AIs response\n",
        "  response = AIMessage(\n",
        "      content=res.content\n",
        "      )\n",
        "\n",
        "  message.append(response)\n",
        "\n",
        "  return res.content"
      ],
      "metadata": {
        "id": "RZ1LTiG-CI1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gaining Inferences"
      ],
      "metadata": {
        "id": "lMPzxdLDrcPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversate(\"What is new hyper performant Vision Object Classification task? Provide references.\"))"
      ],
      "metadata": {
        "id": "F3C1klY0B_ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "523de5c4-1bf9-4061-d0be-0b57ef9f0f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A new hyper-performant vision object classification task refers to the development of advanced techniques and models that achieve exceptional performance in accurately identifying and classifying objects in images or videos. While the provided contexts do not directly mention a specific new hyper-performant vision object classification task, they do contain relevant information on computer vision research.\n",
            "\n",
            "Some references that can provide insights into advancements in this field include:\n",
            "\n",
            "1. \"Multi-task learning using uncertainty to weigh losses for scene geometry and semantics\" by Kendall, A., Gal, Y., and Cipolla, R. (2018) in the Computer Vision and Pattern Recognition conference.\n",
            "\n",
            "2. \"Classifying and segmenting microscopy images using convolutional multiple instance learning\" by Kraus, O.Z., Ba, L.J., and Frey, B. (2015) in the arXiv preprint arXiv:1511.05286.\n",
            "\n",
            "3. \"Retrieving actions in movies\" by Laptev, I., and Pérez, P. (2007) in the International Conference on Computer Vision.\n",
            "\n",
            "4. \"Microsoft COCO: Common objects in context\" by Lin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., and Zitnick, C.L. (2014) in the European Conference on Computer Vision.\n",
            "\n",
            "5. \"SSD: High-Performance Neural Networks for Visual Object Classification\" by Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.Y., and Berg, A.C.\n",
            "\n",
            "These references cover a range of topics and techniques related to computer vision and can provide valuable insights into advancements in hyper-performant vision object classification tasks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hqVRAvNKg4RM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}